"""
ë¡œê·¸ í…Œì´ë¸” ê´€ë ¨ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ í´ë˜ìŠ¤ë“¤
"""
import os
import random
import threading
import time
from PyQt6.QtCore import QThread, pyqtSignal
from core.collector import ADBLogCollector
from core.parser import LogParser
from .log_model import compute_filtered_indices_and_matches


class LogcatThread(QThread):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ logcatì„ ìˆ˜ì§‘í•˜ëŠ” ìŠ¤ë ˆë“œ (core.collector ë˜í¼)"""
    log_received = pyqtSignal(str)  # ë¡œê·¸ ë¼ì¸ì„ ì „ë‹¬í•˜ëŠ” ì‹œê·¸ë„
    error_occurred = pyqtSignal(str)  # ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ëŠ” ì‹œê·¸ë„
    
    def __init__(self, parent=None, logcat_filter='*:V', buffer='main', format_type='threadtime'):
        super().__init__(parent)
        self.collector = ADBLogCollector(logcat_filter=logcat_filter, buffer=buffer, format_type=format_type)
        self.collector.on_log_received = self._on_log_received
        self.collector.on_error = self._on_error
    
    def _on_log_received(self, line: str):
        """ì½œë°±: ë¡œê·¸ ìˆ˜ì‹ """
        self.log_received.emit(line)
    
    def _on_error(self, error: str):
        """ì½œë°±: ì—ëŸ¬ ë°œìƒ"""
        self.error_occurred.emit(error)
    
    def run(self):
        """logcat ì‹¤í–‰"""
        self.collector.collect()
    
    def stop(self):
        """logcat ì¤‘ì§€"""
        self.collector.stop()
    
    def pause(self):
        """ì¼ì‹œì •ì§€"""
        self.collector.pause()
    
    def resume(self):
        """ì¬ê°œ"""
        self.collector.resume()
    
    @property
    def is_running(self):
        """ì‹¤í–‰ ì¤‘ ì—¬ë¶€"""
        return self.collector.is_running
    
    @property
    def is_paused(self):
        """ì¼ì‹œì •ì§€ ì—¬ë¶€"""
        return self.collector.is_paused


class FilterApplyThread(QThread):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í•„í„° ì ìš© ë° UI ì—…ë°ì´íŠ¸ ì¤€ë¹„"""
    batch_ready = pyqtSignal(list, int, int)  # ë°°ì¹˜ ë°ì´í„°, ì‹œì‘ ì¸ë±ìŠ¤, ì´ ê°œìˆ˜
    filter_complete = pyqtSignal(int)  # í•„í„° ì™„ë£Œ (ì´ ê°œìˆ˜)
    
    def __init__(self, all_logs, active_filters, filter_table, evaluate_filter_func):
        super().__init__()
        self.all_logs = all_logs
        self.active_filters = active_filters
        self.filter_table = filter_table
        self.evaluate_filter = evaluate_filter_func
        self.should_cancel = False
        self.batch_size = 10000  # ë°°ì¹˜ í¬ê¸°
    
    def run(self):
        """í•„í„° ì ìš© ë° ë°°ì¹˜ ì¤€ë¹„"""
        try:
            # í™œì„±í™”ëœ í•„í„° ìˆ˜ì§‘
            enabled_filters = []
            for row in range(self.filter_table.rowCount()):
                checkbox = self.filter_table.cellWidget(row, 0)
                if checkbox and checkbox.isChecked():
                    filter_index = checkbox.property('filter_index')
                    if filter_index is not None and 0 <= filter_index < len(self.active_filters):
                        enabled_filters.append(self.active_filters[filter_index])
            
            show_filters = [f for f in enabled_filters if f.get('type', 'Show') == 'Show']
            ignore_filters = [f for f in enabled_filters if f.get('type', 'Show') == 'Ignore']
            
            # í•„í„° ë¹„í™œì„±í™” ëª¨ë“œ
            FILTER_DISABLED = True
            
            # í•„í„°ë§ëœ ë¡œê·¸ ìˆ˜ì§‘
            filtered_logs = []
            for log_data in self.all_logs:
                if self.should_cancel:
                    return
                
                if FILTER_DISABLED:
                    filtered_logs.append((log_data, None))
                else:
                    # Ignore í•„í„° ì²´í¬
                    if ignore_filters:
                        should_ignore = False
                        for f in ignore_filters:
                            if self.evaluate_filter(f, log_data):
                                should_ignore = True
                                break
                        if should_ignore:
                            continue
                    
                    # Show í•„í„° ì²´í¬
                    matched_filter = None
                    if show_filters:
                        for f in show_filters:
                            if self.evaluate_filter(f, log_data):
                                matched_filter = f
                                break
                        if matched_filter is None:
                            continue
                    elif not enabled_filters:
                        matched_filter = None
                    
                    filtered_logs.append((log_data, matched_filter))
                
                # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‹œê·¸ë„ ì „ì†¡
                if len(filtered_logs) >= self.batch_size:
                    self.batch_ready.emit(filtered_logs.copy(), len(filtered_logs) - self.batch_size, len(self.all_logs))
                    filtered_logs.clear()
            
            # ë§ˆì§€ë§‰ ë°°ì¹˜ ì „ì†¡
            if filtered_logs:
                self.batch_ready.emit(filtered_logs, len(self.all_logs) - len(filtered_logs), len(self.all_logs))
            
            # ì™„ë£Œ ì‹œê·¸ë„
            total_filtered = len(self.all_logs) if FILTER_DISABLED else len([l for l in self.all_logs if True])  # ì‹¤ì œë¡œëŠ” í•„í„°ë§ëœ ê°œìˆ˜
            self.filter_complete.emit(total_filtered)
        except Exception as e:
            import logging
            logging.getLogger(__name__).error(f"[FilterThread] ì˜¤ë¥˜: {str(e)}", exc_info=True)
    
    def cancel(self):
        """ì·¨ì†Œ"""
        self.should_cancel = True


class PrepareModelThread(QThread):
    """ì›Œì»¤ì—ì„œ í•„í„° ì ìš© ê³„ì‚° í›„, ë©”ì¸ì—ì„œ set_prepared_dataë§Œ í˜¸ì¶œí•˜ë„ë¡ ê²°ê³¼ ì „ë‹¬"""
    prepared_data = pyqtSignal(list, list, list)  # all_logs, filtered_indices, matched_filters

    def __init__(self, logs: list, filters: list):
        super().__init__()
        self.logs = logs
        self.filters = filters

    def run(self):
        filtered_indices, matched_filters = compute_filtered_indices_and_matches(self.logs, self.filters)
        self.prepared_data.emit(self.logs, filtered_indices, matched_filters)


class FileLoadThread(QThread):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¡œê·¸ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ìŠ¤ë ˆë“œ"""
    log_batch_parsed = pyqtSignal(list)  # ë°°ì¹˜ ë‹¨ìœ„ë¡œ íŒŒì‹±ëœ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
    progress_updated = pyqtSignal(int, int, int)  # ì§„í–‰ë¥ , í˜„ì¬ ì¤„, ì „ì²´ ì¤„
    load_complete = pyqtSignal(int)  # ë¡œë“œ ì™„ë£Œ (ì „ì²´ ì¤„ ìˆ˜)
    load_error = pyqtSignal(str)  # ì—ëŸ¬ ë©”ì‹œì§€
    
    def __init__(self, file_path: str, parser: LogParser):
        super().__init__()
        self.file_path = file_path
        self.parser = parser
        self.batch_size = 50000  # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (í° íŒŒì¼ ì„±ëŠ¥ ìµœì í™”)
        self.should_cancel = False
    
    def run(self):
        """íŒŒì¼ ë¡œë“œ ì‹¤í–‰ - Rust íŒŒì¼ I/O + íŒŒì‹± ì‚¬ìš© (ìµœê³  ì„±ëŠ¥)"""
        try:
            import logging
            logger = logging.getLogger(__name__)
            
            # Rust íŒŒì¼ íŒŒì„œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            has_use_rust = hasattr(self.parser, 'use_rust')
            use_rust_value = getattr(self.parser, 'use_rust', False) if has_use_rust else False
            has_rust_parser = hasattr(self.parser, 'rust_parser')
            rust_parser_value = getattr(self.parser, 'rust_parser', None) if has_rust_parser else None
            has_parse_file_chunk = hasattr(rust_parser_value, 'parse_file_chunk') if rust_parser_value is not None else False
            
            use_rust_file_parsing = (
                has_use_rust
                and use_rust_value
                and has_rust_parser
                and rust_parser_value is not None
                and has_parse_file_chunk
            )
            
            # ë””ë²„ê¹…: ê° ì¡°ê±´ í™•ì¸
            logger.debug(f"[FileLoad] Rust íŒŒì„œ ê°ì§€:")
            logger.debug(f"  - hasattr(parser, 'use_rust'): {has_use_rust}")
            logger.debug(f"  - parser.use_rust: {use_rust_value}")
            logger.debug(f"  - hasattr(parser, 'rust_parser'): {has_rust_parser}")
            logger.debug(f"  - parser.rust_parser is not None: {rust_parser_value is not None}")
            logger.debug(f"  - hasattr(rust_parser, 'parse_file_chunk'): {has_parse_file_chunk}")
            logger.debug(f"  - ìµœì¢… ê²°ê³¼: use_rust_file_parsing = {use_rust_file_parsing}")
            
            if use_rust_file_parsing:
                # Rust ìŠ¤íŠ¸ë¦¬ë° íŒŒì„œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                has_streaming = hasattr(rust_parser_value, 'parse_file_streaming')
                logger.info(f"[FileLoad] has_streaming = {has_streaming}")
                logger.info(f"[FileLoad] rust_parser í•¨ìˆ˜ ëª©ë¡: {dir(rust_parser_value)}")
                
                if has_streaming:
                    # Rust ìŠ¤íŠ¸ë¦¬ë° íŒŒì„œ ì‚¬ìš© (O(n) - ê°€ì¥ íš¨ìœ¨ì , íŒŒì¼ í•œ ë²ˆë§Œ ì½ìŒ)
                    logger.info(f"[FileLoad] ğŸš€ Rust ìŠ¤íŠ¸ë¦¬ë° íŒŒì„œ ì‚¬ìš© - ë°°ì¹˜ í¬ê¸°: {self.batch_size}")
                    
                    parsed_count = [0]  # í´ë¡œì €ì—ì„œ ìˆ˜ì •í•˜ê¸° ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ
                    
                    def on_chunk_parsed(parsed_dicts, current_line, total_lines):
                        """Rustì—ì„œ ì²­í¬ë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” ì½œë°±"""
                        print(f"[PID {os.getpid()}] [Thread {threading.get_ident()}] [FileLoad] Rust ìŠ¤íŠ¸ë¦¬ë° íŒŒì„œ ì²­í¬ íŒŒì‹± - í˜„ì¬ ì¤„: {current_line}, ì „ì²´ ì¤„: {total_lines}")
                        if self.should_cancel:
                            return False  # ì¤‘ë‹¨
                        
                        batch = []
                        for parsed_dict in parsed_dicts:
                            if parsed_dict:
                                timestamp = parsed_dict.get('timestamp', '')
                                level = parsed_dict.get('level', '-')
                                display = parsed_dict.get('display', 'Main')
                                tag = parsed_dict.get('tag', 'Unknown')
                                message = parsed_dict.get('message', '')
                                log_tuple = (timestamp, level, display, tag, message)
                                batch.append(log_tuple)
                        
                        if batch:
                            self.log_batch_parsed.emit(batch)
                            parsed_count[0] += len(batch)
                        
                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                        progress = int((current_line / total_lines) * 100) if total_lines > 0 else 0
                        self.progress_updated.emit(progress, current_line, total_lines)

                        time.sleep(0.02)
                        return True  # ê³„ì† ì§„í–‰
                    
                    # Rust ìŠ¤íŠ¸ë¦¬ë° íŒŒì„œ í˜¸ì¶œ (íŒŒì¼ì„ í•œ ë²ˆë§Œ ì½ìŒ)
                    self.parser.rust_parser.parse_file_streaming(
                        self.file_path, self.batch_size, on_chunk_parsed
                    )
                    
                    # ì™„ë£Œ
                    if not self.should_cancel:
                        self.load_complete.emit(parsed_count[0])
   
        except Exception as e:
            import logging
            logging.getLogger(__name__).error(f"[FileLoad] íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            self.load_error.emit(str(e))
    
    def cancel(self):
        """ë¡œë“œ ì·¨ì†Œ"""
        self.should_cancel = True
